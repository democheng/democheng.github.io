---
layout:     post
title:      自动驾驶-定位-卡尔曼滤波-科普篇
subtitle:   Kalman Filter, localization for self-driving, Popular science
date:       2018-11-07
author:     democheng
header-img: img/self-driving/Waymo-Minivan.jpg
catalog: true
tags:
    - 自动驾驶
    - 定位
    - 卡尔曼滤波
    - self-driving
    - localization
    - Kalman Filter
---

## 新的篇章(new start)

从本篇博客起，会以**自动驾驶**为专题，写一系列博客，每个篇章分为三级：科普篇，公式篇，拓展篇，（传感器篇）:

- 科普篇：用更多的动图，更少的公式，更形象的例子，解释最基本的原理；
- 公式篇：推导最基本的公式；
- 拓展篇：介绍该算法可以用在哪些领域，有哪些代表性的论文，同时推荐github上相关的热门项目；
- 传感器篇：介绍该算法可能使用到的传感器；

博客内容参考[Artificial Intelligence for Robotics](https://www.udacity.com/course/artificial-intelligence-for-robotics--cs373)。


## 适合人群(for the crowd)

没有任何相关背景的人群，特别是非机器人领域的程序猿，可以很快地了解"概率机器人"这个领域。

## 最简单的卡尔曼滤波示例（naive demo for Kalman Filter）

---

我们先抛开历史简介，抛开数学推导，先来看看最简单的Kalman Filter的示例(如下图所示)：

![kfanimation](https://github.com/democheng/PythonRobotics/raw/master/kalmanfilter.gif)

---

## 卡尔曼滤波简介(intro to Kalman Filter)

[Kalman filter(卡尔曼滤波)](https://en.wikipedia.org/wiki/Kalman_filter)，使用一系列"包含统计噪声和不确定性的观测值"，来估计未知的状态的联合概率分布，这种算法比单独使用一个量测估计要准确。好的，文绉绉的定义的翻译到此为止，现在用大白话来翻译一下Kalman Filter的示例：
- 红色：机器人，待估计的状态仅包含“位置”（即在x轴上的坐标）
- 黑色：门，作为地图，这里是已知信息
- 绿色：门的位置和它们的不确定度，事先有人量测好的各个门的位置，但是因为量测仪器的精度有限，因此，会有一定的误差（不确定度）
- 蓝色：机器人位置和它的误差（不确定度）
- 额外说明：这里的“位置”和其“误差”（不确定度）用高斯分布表示，“位置”即“均值”，“误差”即“方差”；高斯分布会在这个示例之后简要介绍

一开始，机器人在0的位置，因为x轴的0处有一个标识，因此有一个很高的置信度；但是，除了0刻度以外，就没有其他刻度了，因此需要我们对机器人的“位置”进行估计/计算。

假设我们对机器人设定好了程序，让它以0.5m/s的速度，向x正轴前行，因为我们用的传感器比较差，虽然程序告诉它了速度，但传达到轮子最终执行的时候，总会有那么点误差（不确定度），这里假设误差为0.04(m/s)^2；

假设我们在机器人上检测了“检测门”的传感器，当这个传感器距离门小于0.01m的时候，可以检测到门的存在；

假设在x正轴方向上有5扇一模一样的门，我们事先通过测距的方式得到了各个门的位置，但是因为量测仪器的精度有限，因此，会有一定的误差（不确定度）。

好的，机器人开始运行，由于没有外界信息的输入，机器人虽然以为自己0.5m/s的速度匀速前行，但是不确定度的存在，导致它现在“位置”变得越来越不可信，正如图中所示，真正可能存在的位置越来越宽；我们把这个过程称之为“预测”（predict）。

还好，我们帮它提前准备好了“地图”，当它遇到第一个门的时候，虽然门的不确定度也不低，但是由于高斯分布的特性（后续解释），两个高斯分布在一起产生了不可思议的“化学反应”，机器人的不确定度神奇地降低了；我们把这个过程称之为量测“更新”（update），其中，量测是指“检测”到门，并从事先的地图中拿到了门的信息，融合进机器人的位置估计/计算中，使得机器人的“位置”更加可信。

之后的故事就是“重复之前的故事”，没有额外信息输入的时候，机器人的不确定度越来越大，又遇到门的时候，不确定度骤降......

**小结**一下：卡尔曼滤波，就是不断**重复**“预测”和“更新”的过程，“预测”由于没有额外信息输入，误差（不确定度）不断增大；“更新”由于有额外信息输入，误差（不确定度）骤降；

## 高斯函数简介

我们这里就不照搬[高斯函数/正态分布](https://www.udacity.com/course/artificial-intelligence-for-robotics--cs373)的定义了，结合示例，我们用一维的情况介绍一下高斯函数：

制作地图的时候，假设我们用的精度较差的激光测距仪测量门的坐标x，每一扇门我们都测量10次，然后把这10次的测量结果求平均得到mean，求方差得到variance，其中，mean即我们最终使用的门的位置，variance则是表达该门的位置的不确定度。

理想情况下，这些门的不确定度（variance）完全相同，因为所有门都是一模一样的，测量仪器也是同一个。

## 方差对比

![gaussian](https://github.com/democheng/democheng.github.io/raw/master/img/self-driving/gaussian.jpg)

上图给出了四个不同的高斯分布的示例，均值mean控制曲线的中间位置，方差variance控制曲线的张口大小；张口越小，说明符合该分布的数据点越集中，得到的结果越可信；张口越大，说明该分布的数据点越发散，得到的结果越不可信；

对于机器人的位置估计/计算来说，我们肯定是希望张口越小越好。


## 高斯函数的计算
<img src="https://latex.codecogs.com/svg.latex?\Large&space;g(x)={\frac {1}{\sigma {\sqrt {2\pi }}}}e^{-{\frac {1}{2}\left({\frac {x-\mu }{\sigma }}\right)^{2}}.}" title="gaussian fuction" />

给定均值mean、方差variance和某点x，带入上式即可求x得概率密度，例如：

mean = 10，variance = 4， x = 8， P(x) = 0.120985

从上图示例就可以看出来，当x = mean的时候，P(x)最大；

## 运动预测

运动预测本质上是“全概率”的“卷积”过程，这个会放在后续的“蒙特卡洛定位”部分来讲。

“位置”（均值）预测：
<img src="https://latex.codecogs.com/svg.latex?\Large&space;mean_{new} = mean_{old} + mean_{motion}" title="mean predict" />

“不确定度”（方差）预测：
<img src="https://latex.codecogs.com/svg.latex?\Large&space;variance_{new} = variance_{old} + variance_{motion}" title="variance predict" />

## 量测更新